# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_xnTUGI7AyRLuLGlc7wZM6OTiextAQ93
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import cv2
import timm  # Advanced deep learning models
from sklearn.model_selection import train_test_split
import albumentations as A  # Advanced image processing
from albumentations.pytorch import ToTensorV2
import shap  # Explainability
import torch.nn.functional as F

# Mount Google Drive for dataset access in Google Colab
from google.colab import drive

drive.mount('/content/drive')

# Load dataset from Google Drive
DATASET_PATH = "/content/drive/MyDrive/SipakMed/"
IMG_SIZE = 256  # Increased image resolution
BATCH_SIZE = 16
EPOCHS = 50  # Increased epochs for better learning
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Advanced Image Preprocessing
transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),
    A.Normalize(mean=[0.5], std=[0.5]),
    ToTensorV2()
])

# Custom Dataset class
class CervicalCancerDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        if self.transform:
            img = self.transform(image=img)['image']
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return img, label

# Load image paths and labels
image_paths = []
labels = []  # 0: Superficial-Intermediate, 1: Parabasal, 2: Koilocytotic, 3: Dyskeratotic, 4: Metaplastic
for class_idx, class_name in enumerate(["Superficial-Intermediate", "Parabasal", "Koilocytotic", "Dyskeratotic", "Metaplastic"]):
    class_path = os.path.join(DATASET_PATH, class_name)
    for img_name in os.listdir(class_path):
        image_paths.append(os.path.join(class_path, img_name))
        labels.append(class_idx)

# Split dataset
train_imgs, test_imgs, train_labels, test_labels = train_test_split(
    image_paths, labels, test_size=0.2, random_state=42, stratify=labels)

train_dataset = CervicalCancerDataset(train_imgs, train_labels, transform)
test_dataset = CervicalCancerDataset(test_imgs, test_labels, transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Define Advanced Model using Timm
class CancerDetectionModel(nn.Module):
    def __init__(self, model_name):
        super(CancerDetectionModel, self).__init__()
        self.base_model = timm.create_model(model_name, pretrained=True, num_classes=5)

    def forward(self, x):
        return self.base_model(x)

# Load Advanced Deep Learning Models
models_dict = {
    "Swin Transformer": "swin_base_patch4_window7_224",
    "ConvNeXt": "convnext_base",
    "EfficientNetV2": "tf_efficientnetv2_l",
    "ViT Transformer": "vit_base_patch16_224"
}

for model_name, model_type in models_dict.items():
    print(f"Training {model_name}...")
    model = CancerDetectionModel(model_type).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.00003)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

    # Training loop
    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        scheduler.step()
        print(f"{model_name} Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}")

    # Save trained model
    model_save_path = f"/content/drive/MyDrive/models/{model_name}_cancer_detection.pth"
    torch.save(model.state_dict(), model_save_path)
    print(f"{model_name} Model Saved at {model_save_path}!")

# Model Evaluation
model.eval()
y_true, y_pred = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

# Compute accuracy
accuracy = np.mean(np.array(y_true) == np.array(y_pred))
print(f"Test Accuracy: {accuracy * 100:.2f}%")